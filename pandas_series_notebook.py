# -*- coding: utf-8 -*-
"""Pandas_Series_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vwy92S95hlkYwnd6G0CmMWOV2ld1jInd

#Getting starting with pandas
"""

import numpy as np
import pandas as pd

#Series
country=['india','pakisthan','china','germany']
pd.Series(country)

#custom index
marks=[67,89,54,32]
subjects=['maths','science','english','hindi']
pd.Series(marks,index=subjects)

#Series attributes
import pandas as pd
country = ['india','pakisthan','china','germany']
s = pd.Series(country)
s.size

s.dtype

pd.Series([1,2,3,1,2,4]).is_unique

s.values

"""# Working with Real world datasets using pandas"""

from google.colab import files
uploaded = files.upload()

!unzip archive.zip

!ls

import pandas as pd

deliveries = pd.read_csv("deliveries.csv")
matches = pd.read_csv("matches.csv")

#head()
matches.head(2)

#tail()
matches.tail(2)

#sample()
matches.sample(2)

#value_counts()
matches['winner'].value_counts()

#sorting
matches.sort_values(by='season',ascending=False)

#count
matches.count()

#sum
matches["result_margin"].sum()

matches['target_runs'].sum()

#mean
matches['target_runs'].mean()

#min
matches['target_overs'].min()

#describe->to generate summary
matches.describe()

#series indexing
x=pd.Series([12,13,14,35,57,58,79,9])
x[1]

#Note:negative indexing doesn't work for series

#slicing
matches[5:7]

#negative slicing
matches[-2:]

#boolean indexing->index label
matches[matches['player_of_match']=='SR Watson']

#editing series
x[1]=100
x

#editing using slicing
x[2:4]=[100,100]
x

#printing length
print(len(matches))

#type of data
matches['target_runs'].dtype

#dir->used to show all attributes and functions of the object
print(dir(matches))

#Type conversion
list(x)

dict(x)

#membership operator
'V Sehwag' in matches['player_of_match'].values

#Looping->for loop
for i in matches['winner']:
    print(i)

#arithmatic operators
100-x

#relational operators
matches['target_overs']>50

#Boolean indexing using size
matches[matches['target_overs']>15].size

#Graphs on series
matches['toss_decision'].value_counts().plot()

#Note:we use value_counts to convert strings into int cuz pandas cannot recognise to plot otherwise

matches.value_counts().head(5).plot(kind='pie')

"""#Some important series methods

"""

#astype
matches['target_runs'].astype(float)

#between
matches[matches['target_overs'].between(10,25)]

#clip
matches['target_overs'].clip(15,25)

#drop duplicates
x=pd.Series([1,2,1,3,4,3,4,5,6,6,7,8,8])
x
x.drop_duplicates(keep='last')

x.drop_duplicates().sum()

#is_null
x.isnull().sum()

#dropna
import numpy as np
y=[1,2,4,5,6,8,np.nan,5,6,8,np.nan,9,np.nan]
Yseries=pd.Series(y)
Yseries
Yseries.dropna()

#nOTE:dropna() works on series or dataframrs not lists

#fillna
Yseries.fillna(7)

matches['target_overs'].fillna(7)

#isin
matches[matches['city'].str.lower().isin(['bangalore','mumbai','kolkata'])]

#apply
matches['high_target']=matches['target_runs'].apply(lambda x:True if x>100 else False)
matches['high_target']

#copy
#subset=matches[matches['city']=='Mumbai'].copy()
subset['target_runs']=200
subset

#nOTE:to make the copy to be permanant you shud give index=false







